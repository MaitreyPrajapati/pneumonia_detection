{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import os \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train images : 5216 \n",
      "# Test images : 624\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "c1 = glob.glob('Data/chest_xray/train/*/*')\n",
    "c2 = glob.glob('Data/chest_xray/test/*/*')\n",
    "\n",
    "print('# Train images : {} \\n# Test images : {}'.format(len(c1), len(c2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading, resizing, classifying images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "          \n",
    "def returnLabel(path):\n",
    "    imgClass = tf.strings.split(path,'/')[-2]\n",
    "    return 0 if imgClass == 'NORMAL' else 1\n",
    "\n",
    "def returnImg(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    imgClass = returnLabel(path)\n",
    "    return tf.image.resize(img, (256,256)), imgClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ParallelMapDataset shapes: ((256, 256, 3), ()), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_path = 'Data/chest_xray/train'\n",
    "list_ds = tf.data.Dataset.list_files(str(train_path+'/*/*'))\n",
    "labeled_ds = list_ds.map(returnImg, num_parallel_calls=AUTOTUNE)\n",
    "labeled_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyHistory(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.acc = []\n",
    "        self.loss_ = []\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.acc.append(logs.get('accuracy'))\n",
    "        self.loss_.append(logs.get('loss'))\n",
    "\n",
    "history = AccuracyHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(8,5, strides=(5,5), padding='SAME', activation='relu', use_bias=True))\n",
    "    model.add(AveragePooling2D(pool_size=(2,2), data_format='channels_last'))\n",
    "    \n",
    "    model.add(Conv2D(10, 5, activation='relu', use_bias=True))\n",
    "    model.add(AveragePooling2D(pool_size=(2,2), strides=(1,1), data_format='channels_last'))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(120, activation='relu', use_bias=True))\n",
    "    model.add(Dense(84, activation='relu', use_bias=True))\n",
    "    model.add(Dense(1, activation='sigmoid', use_bias=True))\n",
    "    \n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(), optimizer=tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07), metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7085 - accuracy: 0.2575\n",
      "Epoch 2/25\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7429\n",
      "Epoch 3/25\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6200 - accuracy: 0.7429\n",
      "Epoch 4/25\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5656 - accuracy: 0.7429\n",
      "Epoch 5/25\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5609 - accuracy: 0.7429\n",
      "Epoch 6/25\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5684 - accuracy: 0.7429\n",
      "Epoch 7/25\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5617 - accuracy: 0.7429\n",
      "Epoch 8/25\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5479 - accuracy: 0.7429\n",
      "Epoch 9/25\n",
      "1/1 [==============================] - 0s 908us/step - loss: 0.5364 - accuracy: 0.7429\n",
      "Epoch 10/25\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5283 - accuracy: 0.7429\n",
      "Epoch 11/25\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5189 - accuracy: 0.7429\n",
      "Epoch 12/25\n",
      "1/1 [==============================] - 0s 965us/step - loss: 0.5068 - accuracy: 0.7429\n",
      "Epoch 13/25\n",
      "1/1 [==============================] - 0s 980us/step - loss: 0.4943 - accuracy: 0.7429\n",
      "Epoch 14/25\n",
      "1/1 [==============================] - 0s 952us/step - loss: 0.4747 - accuracy: 0.7429\n",
      "Epoch 15/25\n",
      "1/1 [==============================] - 0s 975us/step - loss: 0.4571 - accuracy: 0.7431\n",
      "Epoch 16/25\n",
      "1/1 [==============================] - 0s 973us/step - loss: 0.4350 - accuracy: 0.7558\n",
      "Epoch 17/25\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4099 - accuracy: 0.8073\n",
      "Epoch 18/25\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3816 - accuracy: 0.8313\n",
      "Epoch 19/25\n",
      "1/1 [==============================] - 0s 952us/step - loss: 0.3550 - accuracy: 0.8535\n",
      "Epoch 20/25\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3281 - accuracy: 0.8831\n",
      "Epoch 21/25\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3023 - accuracy: 0.8846\n",
      "Epoch 22/25\n",
      "1/1 [==============================] - 0s 867us/step - loss: 0.2799 - accuracy: 0.8970\n",
      "Epoch 23/25\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2745 - accuracy: 0.8811\n",
      "Epoch 24/25\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2877 - accuracy: 0.8800\n",
      "Epoch 25/25\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2691 - accuracy: 0.8825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x64475fb10>"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch = 25\n",
    "batch_size = 128\n",
    "seed = 1 \n",
    "labeled_data = labeled_ds.batch(5300)\n",
    "model = nn_model()\n",
    "\n",
    "model.fit(labeled_data, batch_size=128, epochs=epoch, verbose=1, callbacks=[history])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(model, test_dataset):    \n",
    "    return model.evaluate(test_dataset, verbose = 1, batch_size=128, return_dict=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = 'Data/chest_xray/test'\n",
    "test_ds = tf.data.Dataset.list_files(str(train_path+'/*/*'))\n",
    "test_labeled = test_ds.map(returnImg, num_parallel_calls=AUTOTUNE)\n",
    "test_labeled = test_labeled.batch(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 18s 3s/step - loss: 0.2416 - accuracy: 0.8982\n"
     ]
    }
   ],
   "source": [
    "score = testing(model, test_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
